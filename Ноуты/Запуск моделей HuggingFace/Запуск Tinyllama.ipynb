{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2-TGC7pvw-O"
      },
      "outputs": [],
      "source": [
        "# Install transformers from source - only needed for versions <= v4.34\n",
        "pip install git+https://github.com/huggingface/transformers.git\n",
        "pip install accelerate\n",
        "# Установка переводчика\n",
        "pip install deep_translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ6pLqcQwY7G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from deep_translator import GoogleTranslator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhW8ZjRv3JBA"
      },
      "outputs": [],
      "source": [
        "# Создание экземпляра pipline\n",
        "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v0.6\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "\n",
        "# Создание экземпляра GoogleTranslator\n",
        "rutranslator = GoogleTranslator(source='auto', target='ru')\n",
        "entranslator = GoogleTranslator(source='auto', target='en')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xPqZxxFvp33"
      },
      "outputs": [],
      "source": [
        "def get_answer(system_promts, questions):\n",
        "\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": system_promts},\n",
        "      {\"role\": \"user\", \"content\": questions},\n",
        "  ]\n",
        "\n",
        "  prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "  outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
        "\n",
        "  generated_text = outputs[0]['generated_text']\n",
        "  separator = '<|assistant|>'\n",
        "  text_after_generated = generated_text.split(separator, 1)[-1].strip()\n",
        "  return rutranslator.translate(text_after_generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF1XX2XG0Vzl",
        "outputId": "c18a57b1-bff9-431d-f488-ddfa6743bc7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ответ: Ваш точный вопрос не был задан в подсказке, поэтому я понятия не имею, что вы имели в виду.\n"
          ]
        }
      ],
      "source": [
        "question = entranslator.translate(\"Как часто нужно гулять на свежем воздухе\")\n",
        "system_promt = entranslator.translate(\"Ты дружелюбный чат-бот\")\n",
        "answer = def get_answer(system_promt, question)\n",
        "print(answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
